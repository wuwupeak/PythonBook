学习算法与国家安全

在网络空间之外，学习算法是保护国家的壁垒。每天，国外袭击者都会企图闯进五角大楼、国防承包商以及其他公司和政府机构的计算机。他们的计谋不断变化，能抵抗昨天袭击的方法，今天就已经不管用了。编写代码来侦查并阻止每场袭击，可能会和马其诺防线一样有效，五角大楼的网络司令部十分了解这一点。但如果是恐怖分子的第一次袭击，而且也没有之前的例子供机器学习来参考，那么机器学习就会遇到问题。学习算法会构建正常行为的模型（这样的模型数量很多），标出异常行为，然后召集来“骑兵”（系统管理员）。如果网络战争发生，人类就是总指挥，算法就是步兵。人类速度太慢、数量太少，很快就会被机器人大军歼灭。我们需要自己的机器人军队，而机器学习就像机器人中的西点军校。
网络战争是不对称战争的一个例子，一方的传统军事实力比不上另一方，但仍然可以给对方造成严重伤害。少数恐怖分子只用美工刀就可以撞到双子塔，并让几千名无辜者遇难。当今美国安全最大的威胁就是不对称战争，而且抵抗所有威胁的有效武器就是信息。如果敌人躲不了，那么他也活不了。好消息就是我们有大量信息，但也有坏消息。
美国国家安全局已经对数据产生无限大的胃口，也因此声名狼藉。据估计，每天美国国家安全局窃听着全球10亿多个通话，还有其他通信。但是，抛开隐私问题，它也没有让上百万员工来窃听这些通话、偷看邮件，甚至也不会记录谁和谁通话。绝大多数通话是没有嫌疑的，而专门编写程序来找出有嫌疑的通话又很困难。过去，美国国家安全局利用关键词配对方法，但要应付这个方法也很容易（例如，把爆炸袭击称作“结婚”，把炸弹称作“结婚蛋糕”）。21世纪，这些事就可以交给机器学习。保密是安全局的标志，但安全局局长已经向美国国会证明，通话记录挖掘已经阻止了几十起恐怖威胁。
恐怖分子可隐藏在足球比赛的人群中，但学习算法能辨认他们的相貌。恐怖分子可以在国外制造爆炸事件，但学习算法能找出他们。学习算法还可以做更加精细的事情：将机器人与事件连接起来，这些事件单个看起来并无危害，但集中起来可能就预示着不祥。这种方法本可以阻止“9·11”事件的发生。有一个进一步的转折：一旦确定的程序部署下来，坏人可能会改变其活动，以扰乱该程序。这与自然世界不同，自然世界总是以同样的方式运转。要解决这个问题，就要将机器学习与博弈论相结合，这是我已经在做的工作：别只想着打击对手当前想做的事，要学会巧妙地回避对手对你的学习算法的损害。正如博弈论那样，把各种措施的成本和利益考虑在内，这也有助于找到隐私与安全之间的平衡点。
不列颠之战期间，英国空军阻止了纳粹德国空军的进攻，尽管后者人数比前者多很多。德国飞行员不明白，为什么无论走到哪里，他们总会碰上英国空军。英国有一个秘密武器：雷达，可以在德国飞机越境进入英国领空时，就探测到它们。机器学习就像装了雷达，能够预知未来。别只是回击对手的行动，要预测他们的行动，并先发制人。
一个更确切的例子就是人们熟知的“预知执法”。通过预测犯罪倾向，战略性地将巡逻队集中在最可能需要的地方，同时采取其他预防措施，这样一座城市的警力就能有效地完成更大范围的工作。在许多方面，执法过程就像不对称战争，会用到许多相似的学习算法，无论是在侦查诈骗、揭露犯罪网络，还是普通传统的打击执法中。
机器学习在战争中也将扮演越来越重要的角色。学习算法能有助于驱散战争迷雾，筛选侦察图像，处理后续报告，并整合信息，为指挥官提供战争形势分析。学习算法可以武装军用机器人的大脑，帮助其保持方位，适应地形，把敌机和民用机区别开来，以及进行制导。美国国防部高级研究计划局（DARPA）的领头狗（AlphaDog）能为士兵搬运设备。遥控飞机在学习算法的作用下可自主飞行。虽然它们仍受到人类飞行员的部分控制，但未来的趋势是一个飞行员监控越来越多的遥控飞机群。在未来的军队里，学习算法的数量会大大超过士兵的人数，这将减少许多士兵的伤亡。
